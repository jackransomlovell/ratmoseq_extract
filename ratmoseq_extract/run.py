from pathlib import Path
from tqdm import tqdm
import uuid
from copy import deepcopy
import os
from os import dirname
from os.path import join, exists
import warnings
import ruamel.yaml as yaml
import numpy as np
import h5py

from ratmoseq_extract.extract import extract_chunk
from ratmoseq_extract.sam2 import load_dlc
from ratmoseq_extract.proc import check_filter_sizes, get_strels, get_bground
from ratmoseq_extract.io import (
    write_extracted_chunk_to_h5, 
    make_output_movie, 
    load_movie_data,
    write_frames_preview,
    handle_extract_metadata,
    get_movie_info,
    get_frame_range_indices,
    scalar_attributes,
    gen_batch_sequence,
    write_image,
    create_extract_h5,
    read_yaml
)

def process_extract_batches(
    input_file,
    config_data,
    bground_im,
    roi,
    frame_batches,
    str_els,
    output_mov_path,
    scalars=None,
    h5_file=None,
    video_pipe=None,
    **kwargs,
):
    """
    Compute extracted frames and save them to h5 files and avi files.

    Args:
    input_file (str): path to depth file
    config_data (dict): dictionary containing extraction parameters (autogenerated)
    bground_im (numpy.ndarray):  background image
    roi (numpy.ndarray): roi image
    frame_batches (list): list of batches of frames to serially process.
    str_els (dict): dictionary containing OpenCV StructuringElements
    output_mov_path (str): path and filename of the output movie generated by the extraction
    scalars (list): list of keys to scalar attribute values
    h5file (h5py.File): opened h5 file to write extracted batches to
    video_pipe (subprocess.PIPE): open pipe to location where preview extraction is being written.
    kwargs (dict): Extra keyword arguments.

    Returns:
    """

    for i, frame_range in enumerate(tqdm(frame_batches, desc="Processing batches")):
        raw_chunk = load_movie_data(
            input_file, frame_range, frame_size=bground_im.shape[::-1], **config_data
        )

        offset = config_data["chunk_overlap"] if i > 0 else 0

        # load DLC keypoints if available
        if config_data["dlc_filename"]:
            # get keypoints and bodyparts from config
            csv = Path(input_file).parents[0] / config_data["dlc_filename"]
            bodyparts = config_data["dlc_bodyparts"]
            # load DLC data
            sam2_points = load_dlc(csv, bodyparts, frame_range, roi)
            # add to config_data
            config_data["sam2_points"] = sam2_points

        # Get crop-rotated frame batch
        results = extract_chunk(
            **config_data,
            **str_els,
            chunk=raw_chunk,
            roi=roi,
            bground=bground_im
        )


        # Offsetting frame chunk by CLI parameter defined option: chunk_overlap
        frame_range = frame_range[offset:]

        if h5_file is not None:
            write_extracted_chunk_to_h5(
                h5_file, results, config_data, scalars, frame_range, offset
            )

        # Create array for output movie with filtered video and cropped mouse on the top left
        output_movie = make_output_movie(results, config_data, offset)

        # Writing frame batch to mp4 file
        video_pipe = write_frames_preview(
            output_mov_path,
            output_movie,
            pipe=video_pipe,
            close_pipe=False,
            fps=config_data["fps"],
            frame_range=list(frame_range),
            depth_max=config_data["max_height"],
            depth_min=config_data["min_height"],
            progress_bar=config_data.get("progress_bar", False),
        )

    # Check if video is done writing. If not, wait.
    if video_pipe is not None:
        video_pipe.communicate()

def check_completion_status(status_filename):
    """
    Read a results_00.yaml (status file) and checks whether the session has been
    fully extracted.

    Args:
    status_filename (str): path to results_00.yaml

    Returns:
    complete (bool): If True, data has been extracted to completion.
    """

    if exists(status_filename):
        return read_yaml(status_filename)["complete"]
    return False

def extract_wrapper(input_file, output_dir, config_data, num_frames=None, skip=False):
    """
    Extract depth videos.

    Args:
    input_file (str): path to depth file
    output_dir (str): path to directory to save results in.
    config_data (dict): dictionary containing extraction parameters.
    num_frames (int): number of frames to extract.
    skip (bool): indicates whether to skip file if already extracted
    extract (function): extraction function state

    Returns:
    output_dir (str): path to directory containing extraction
    """
    print("Processing:", input_file)
    # get the basic metadata

    # ensure 'get_cmd' and 'run_cmd' are not in config_data or get_bground_im_file will fail
    config_data = {
        k: v
        for k, v in config_data.items()
        if k not in ("get_cmd", "run_cmd", "extensions")
    }

    status_dict = {
        "complete": False,
        "skip": False,
        "uuid": str(uuid.uuid4()),
        "metadata": "",
        "parameters": deepcopy(config_data),
    }

    # save input directory path
    in_dirname = dirname(input_file)

    # If input file is compressed (tarFile), returns decompressed file path and tar bool indicator.
    # Also gets loads respective metadata dictionary and timestamp array.
    acquisition_metadata, config_data["timestamps"], config_data["tar"] = (
        handle_extract_metadata(input_file, in_dirname)
    )

    # updating input_file reference to open tar file object if input file ends with [.tar/.tar.gz]
    if config_data["tar"] is not None:
        input_file = config_data["tar"]

    config_data["finfo"] = get_movie_info(input_file, **config_data)

    if config_data["finfo"]["nframes"] is None:
        config_data["finfo"]["nframes"] = len(config_data["timestamps"])

    status_dict["metadata"] = acquisition_metadata  # update status dict

    # Getting number of frames to extract
    if num_frames is None:
        nframes = int(config_data["finfo"]["nframes"])
    elif num_frames > config_data["finfo"]["nframes"]:
        warnings.warn(
            "Requested more frames than video includes, extracting whole recording..."
        )
        nframes = int(config_data["finfo"]["nframes"])
    elif isinstance(num_frames, int):
        nframes = num_frames

    config_data = check_filter_sizes(config_data)

    # Compute total number of frames to include from an initial starting point.
    total_frames, first_frame_idx, last_frame_idx = get_frame_range_indices(
        *config_data["frame_trim"], nframes
    )

    scalars_attrs = scalar_attributes()
    scalars = list(scalars_attrs)

    # Get frame chunks to extract
    frame_batches = gen_batch_sequence(
        last_frame_idx,
        config_data["chunk_size"],
        config_data["chunk_overlap"],
        offset=first_frame_idx,
    )

    # set up the output directory
    if output_dir is None:
        output_dir = join(in_dirname, "proc")
    else:
        if in_dirname not in output_dir:
            output_dir = join(in_dirname, output_dir)

    if not exists(output_dir):
        os.makedirs(output_dir)

    # Ensure index is int
    if isinstance(config_data["bg_roi_index"], list):
        config_data["bg_roi_index"] = config_data["bg_roi_index"][0]

    output_filename = f'results_{config_data["bg_roi_index"]:02d}'
    status_filename = join(output_dir, f"{output_filename}.yaml")
    movie_filename = join(output_dir, f"{output_filename}.mp4")
    results_filename = join(output_dir, f"{output_filename}.h5")

    # Check if session has already been extracted
    if check_completion_status(status_filename) and skip:
        print("Skipping...")
        return

    with open(status_filename, "w") as f:
        yaml.safe_dump(status_dict, f)

    # Get Structuring Elements for extraction
    str_els = get_strels(config_data)

    roi = np.ones(config_data["finfo"]["dims"], dtype=np.uint8)
    bground_im, first_frame = get_bground(input_file, config_data, output_dir=output_dir)

    # Debugging option: DTD has no effect on extraction results unless dilate iterations > 1
    if config_data.get("detected_true_depth", "auto") == "auto":
        config_data["true_depth"] = np.median(bground_im[roi > 0])
    else:
        config_data["true_depth"] = int(config_data["detected_true_depth"])

    print("Detected true depth:", config_data["true_depth"])


    extraction_data = {
        "bground_im": bground_im,
        "roi": roi,
        "first_frame": first_frame,
        "first_frame_idx": first_frame_idx,
        "last_frame_idx": last_frame_idx,
        "nframes": total_frames,
        "frame_batches": frame_batches,
    }

    # farm out the batches and write to an hdf5 file
    with h5py.File(results_filename, "w") as f:
        # Write scalars, roi, acquisition metadata, etc. to h5 file
        create_extract_h5(
            **extraction_data,
            h5_file=f,
            acquisition_metadata=acquisition_metadata,
            config_data=config_data,
            status_dict=status_dict,
            scalars_attrs=scalars_attrs,
        )

        # Write crop-rotated results to h5 file and write video preview mp4 file
        process_extract_batches(
            **extraction_data,
            h5_file=f,
            input_file=input_file,
            config_data=config_data,
            scalars=scalars,
            str_els=str_els,
            output_mov_path=movie_filename,
        )

    print()

    status_dict["complete"] = True
    if status_dict["parameters"].get("true_depth") is None:
        # config_data.get('true_depth') is numpy.float64 and yaml.safe_dump can't represent the object
        status_dict["parameters"]["true_depth"] = float(config_data.get("true_depth"))
    with open(status_filename, "w") as f:
        yaml.safe_dump(status_dict, f)

    return output_dir