{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be1b44bb-188b-4b84-8978-f2c2b0c756b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc6...\n",
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3433ff87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Thu_Jan_28_19:32:09_PST_2021\n",
      "Cuda compilation tools, release 11.2, V11.2.142\n",
      "Build cuda_11.2.r11.2/compiler.29558016_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6741391-d5bf-42b5-8d86-a7b6917452cb",
   "metadata": {},
   "source": [
    "# loading\n",
    "- we need to tell DLC where our config is, and what videos we want to infer\n",
    "- make sure to change the paths below!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6f141fd-c10d-4e70-9109-85d0e7ca53ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with the path to your DLC config\n",
    "config = '/n/groups/datta/jlove/data/rat_seq/rat_seq_paper/keypoint_model/config-v2.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1f72486-5f86-4deb-a548-809b3f2449d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = Path('/n/groups/datta/jlove/data/rat_seq/rat_seq_paper/data/4weeks')\n",
    "videos = list(videos.glob('**/ir_clipped.avi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36b48d06-ce11-4048-8d91-b00c81bffe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = ['/n/groups/datta/jlove/data/tst.avi']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1aceb4-1c2f-4a22-b3a7-157a7b014be3",
   "metadata": {},
   "source": [
    "# DLC\n",
    "- call the three functions below to get keypoints, filter them, and then generate mp4 videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "307b42ec-2991-4a4b-93ed-cc587e65feb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-50000 for model /n/groups/datta/jlove/data/rat_seq/rat_seq_paper/keypoint_model/dlc-models/iteration-0/KeypointMoSeqDLCOct18-trainset95shuffle1\n",
      "Starting analysis in dynamic cropping mode with parameters: (True, 0.5, 10)\n",
      "Switching batchsize to 1, num_outputs (per animal) to 1 and TFGPUinference to False (all these features are not supported in this mode).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jal5475/.miniconda/envs/DEEPLABCUT/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2025-03-13 18:42:33.921045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:18:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /n/groups/datta/jlove/data/tst.avi\n",
      "Loading  /n/groups/datta/jlove/data/tst.avi\n",
      "Duration of video [s]:  120.0 , recorded with  30.0 fps!\n",
      "Overall # of frames:  3600  found with (before cropping) frame dimensions:  640 576\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3600/3600 [01:01<00:00, 58.70it/s]\n",
      "/home/jal5475/.miniconda/envs/DEEPLABCUT/lib/python3.10/site-packages/deeplabcut/utils/auxiliaryfunctions.py:470: FutureWarning: Starting with pandas version 3.0 all arguments of to_hdf except for the argument 'path_or_buf' will be keyword-only.\n",
      "  DataMachine.to_hdf(dataname, \"df_with_missing\", format=\"table\", mode=\"w\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /n/groups/datta/jlove/data...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_KeypointMoSeqDLCOct18shuffle1_50000'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.analyze_videos(config, videos, videotype='avi', shuffle=1, trainingsetindex=0, gputouse=0, save_as_csv=True, destfolder=None, dynamic=(True, .5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bb2365f-3ab1-455f-abf7-abb605d8e003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering with median model /n/groups/datta/jlove/data/tst.avi\n",
      "Saving filtered csv poses!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jal5475/.miniconda/envs/DEEPLABCUT/lib/python3.10/site-packages/deeplabcut/post_processing/filtering.py:298: FutureWarning: Starting with pandas version 3.0 all arguments of to_hdf except for the argument 'path_or_buf' will be keyword-only.\n",
      "  data.to_hdf(outdataname, \"df_with_missing\", format=\"table\", mode=\"w\")\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.filterpredictions(config, videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02f8cd6f-afae-4bd8-a615-cb769c172587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process video: /n/groups/datta/jlove/data/tst.avi\n",
      "Loading /n/groups/datta/jlove/data/tst.avi and data.\n",
      "Duration of video [s]: 120.0, recorded with 30.0 fps!\n",
      "Overall # of frames: 3600 with cropped frame dimensions: 640 576\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3600/3600 [00:09<00:00, 390.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_labeled_video(config, videos, filtered=True, pcutoff=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00729bf1-c7ed-4b84-bd6d-90d3310a12af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEPLABCUT",
   "language": "python",
   "name": "deeplabcut"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
