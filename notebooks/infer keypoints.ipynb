{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be1b44bb-188b-4b84-8978-f2c2b0c756b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc6...\n",
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6741391-d5bf-42b5-8d86-a7b6917452cb",
   "metadata": {},
   "source": [
    "# loading\n",
    "- we need to tell DLC where our config is, and what videos we want to infer\n",
    "- make sure to change the paths below!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6f141fd-c10d-4e70-9109-85d0e7ca53ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with the path to your DLC config\n",
    "config = '/n/groups/datta/jlove/data/rat_seq/rat_seq_paper/keypoint_model/config-v2.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f72486-5f86-4deb-a548-809b3f2449d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = Path('/n/groups/datta/jlove/data/rat_seq/rat_seq_paper/data/4weeks')\n",
    "videos = list(videos.glob('**/ir_clipped.avi'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1aceb4-1c2f-4a22-b3a7-157a7b014be3",
   "metadata": {},
   "source": [
    "# DLC\n",
    "- call the three functions below to get keypoints, filter them, and then generate mp4 videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87fa2063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvideos\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'list[str]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvideotype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtrainingsetindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mgputouse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msave_as_csv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0min_random_order\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdestfolder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbatchsize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcropping\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'list[int] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mTFGPUinference\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdynamic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'tuple[bool, float, int]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmodelprefix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrobust_nframes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mallow_growth\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0muse_shelve\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mauto_track\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_tracks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcalibrate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0midentity_only\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0muse_openvino\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Engine | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mtorch_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "\u001b[0;32mdef\u001b[0m \u001b[0manalyze_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvideos\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvideotype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtrainingsetindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mgputouse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msave_as_csv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0min_random_order\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdestfolder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbatchsize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcropping\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mTFGPUinference\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdynamic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmodelprefix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrobust_nframes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mallow_growth\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0muse_shelve\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mauto_track\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_tracks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcalibrate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0midentity_only\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0muse_openvino\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEngine\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mtorch_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Makes prediction based on a trained network.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The index of the trained network is specified by parameters in the config file\u001b[0m\n",
      "\u001b[0;34m    (in particular the variable 'snapshotindex').\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The labels are stored as MultiIndex Pandas Array, which contains the name of\u001b[0m\n",
      "\u001b[0;34m    the network, body part name, (x, y) label position in pixels, and the\u001b[0m\n",
      "\u001b[0;34m    likelihood for each frame per body part. These arrays are stored in an\u001b[0m\n",
      "\u001b[0;34m    efficient Hierarchical Data Format (HDF) in the same directory where the video\u001b[0m\n",
      "\u001b[0;34m    is stored. However, if the flag save_as_csv is set to True, the data can also\u001b[0m\n",
      "\u001b[0;34m    be exported in comma-separated values format (.csv), which in turn can be\u001b[0m\n",
      "\u001b[0;34m    imported in many programs, such as MATLAB, R, Prism, etc.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Parameters\u001b[0m\n",
      "\u001b[0;34m    ----------\u001b[0m\n",
      "\u001b[0;34m    config: str\u001b[0m\n",
      "\u001b[0;34m        Full path of the config.yaml file.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    videos: list[str]\u001b[0m\n",
      "\u001b[0;34m        A list of strings containing the full paths to videos for analysis or a path to\u001b[0m\n",
      "\u001b[0;34m        the directory, where all the videos with same extension are stored.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    videotype: str, optional, default=\"\"\u001b[0m\n",
      "\u001b[0;34m        Checks for the extension of the video in case the input to the video is a\u001b[0m\n",
      "\u001b[0;34m        directory. Only videos with this extension are analyzed. If left unspecified,\u001b[0m\n",
      "\u001b[0;34m        videos with common extensions ('avi', 'mp4', 'mov', 'mpeg', 'mkv') are kept.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    shuffle: int, optional, default=1\u001b[0m\n",
      "\u001b[0;34m        An integer specifying the shuffle index of the training dataset used for\u001b[0m\n",
      "\u001b[0;34m        training the network.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    trainingsetindex: int, optional, default=0\u001b[0m\n",
      "\u001b[0;34m        Integer specifying which TrainingsetFraction to use.\u001b[0m\n",
      "\u001b[0;34m        By default the first (note that TrainingFraction is a list in config.yaml).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    gputouse: int or None, optional, default=None\u001b[0m\n",
      "\u001b[0;34m        Only for the TensorFlow engine (for the PyTorch engine see the ``torch_kwargs``:\u001b[0m\n",
      "\u001b[0;34m        you can use ``device``).\u001b[0m\n",
      "\u001b[0;34m        Indicates the GPU to use (see number in ``nvidia-smi``). If you do not have a\u001b[0m\n",
      "\u001b[0;34m        GPU put ``None``.\u001b[0m\n",
      "\u001b[0;34m        See: https://nvidia.custhelp.com/app/answers/detail/a_id/3751/~/useful-nvidia-smi-queries\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    save_as_csv: bool, optional, default=False\u001b[0m\n",
      "\u001b[0;34m        Saves the predictions in a .csv file.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    in_random_order: bool, optional (default=True)\u001b[0m\n",
      "\u001b[0;34m        Only for the TensorFlow engine.\u001b[0m\n",
      "\u001b[0;34m        Whether or not to analyze videos in a random order.\u001b[0m\n",
      "\u001b[0;34m        This is only relevant when specifying a video directory in `videos`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    destfolder: string or None, optional, default=None\u001b[0m\n",
      "\u001b[0;34m        Specifies the destination folder for analysis data. If ``None``, the path of\u001b[0m\n",
      "\u001b[0;34m        the video is used. Note that for subsequent analysis this folder also needs to\u001b[0m\n",
      "\u001b[0;34m        be passed.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    batchsize: int or None, optional, default=None\u001b[0m\n",
      "\u001b[0;34m        Currently not supported by the PyTorch engine.\u001b[0m\n",
      "\u001b[0;34m        Change batch size for inference; if given overwrites value in ``pose_cfg.yaml``.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    cropping: list or None, optional, default=None\u001b[0m\n",
      "\u001b[0;34m        Currently not supported by the PyTorch engine.\u001b[0m\n",
      "\u001b[0;34m        List of cropping coordinates as [x1, x2, y1, y2].\u001b[0m\n",
      "\u001b[0;34m        Note that the same cropping parameters will then be used for all videos.\u001b[0m\n",
      "\u001b[0;34m        If different video crops are desired, run ``analyze_videos`` on individual\u001b[0m\n",
      "\u001b[0;34m        videos with the corresponding cropping coordinates.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    TFGPUinference: bool, optional, default=True\u001b[0m\n",
      "\u001b[0;34m        Only for the TensorFlow engine.\u001b[0m\n",
      "\u001b[0;34m        Perform inference on GPU with TensorFlow code. Introduced in \"Pretraining\u001b[0m\n",
      "\u001b[0;34m        boosts out-of-domain robustness for pose estimation\" by Alexander Mathis,\u001b[0m\n",
      "\u001b[0;34m        Mert Yüksekgönül, Byron Rogers, Matthias Bethge, Mackenzie W. Mathis.\u001b[0m\n",
      "\u001b[0;34m        Source: https://arxiv.org/abs/1909.11229\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    dynamic: tuple(bool, float, int) triple containing (state, detectiontreshold, margin)\u001b[0m\n",
      "\u001b[0;34m        Currently not supported by the PyTorch engine.\u001b[0m\n",
      "\u001b[0;34m        If the state is true, then dynamic cropping will be performed. That means that\u001b[0m\n",
      "\u001b[0;34m        if an object is detected (i.e. any body part > detectiontreshold), then object\u001b[0m\n",
      "\u001b[0;34m        boundaries are computed according to the smallest/largest x position and\u001b[0m\n",
      "\u001b[0;34m        smallest/largest y position of all body parts. This  window is expanded by the\u001b[0m\n",
      "\u001b[0;34m        margin and from then on only the posture within this crop is analyzed (until the\u001b[0m\n",
      "\u001b[0;34m        object is lost, i.e. <detectiontreshold). The current position is utilized for\u001b[0m\n",
      "\u001b[0;34m        updating the crop window for the next frame (this is why the margin is important\u001b[0m\n",
      "\u001b[0;34m        and should be set large enough given the movement of the animal).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    modelprefix: str, optional, default=\"\"\u001b[0m\n",
      "\u001b[0;34m        Directory containing the deeplabcut models to use when evaluating the network.\u001b[0m\n",
      "\u001b[0;34m        By default, the models are assumed to exist in the project folder.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    robust_nframes: bool, optional, default=False\u001b[0m\n",
      "\u001b[0;34m        Currently not supported by the PyTorch engine.\u001b[0m\n",
      "\u001b[0;34m        Evaluate a video's number of frames in a robust manner.\u001b[0m\n",
      "\u001b[0;34m        This option is slower (as the whole video is read frame-by-frame),\u001b[0m\n",
      "\u001b[0;34m        but does not rely on metadata, hence its robustness against file corruption.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    allow_growth: bool, optional, default=False.\u001b[0m\n",
      "\u001b[0;34m        Only for the TensorFlow engine.\u001b[0m\n",
      "\u001b[0;34m        For some smaller GPUs the memory issues happen. If ``True``, the memory\u001b[0m\n",
      "\u001b[0;34m        allocator does not pre-allocate the entire specified GPU memory region, instead\u001b[0m\n",
      "\u001b[0;34m        starting small and growing as needed.\u001b[0m\n",
      "\u001b[0;34m        See issue: https://forum.image.sc/t/how-to-stop-running-out-of-vram/30551/2\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    use_shelve: bool, optional, default=False\u001b[0m\n",
      "\u001b[0;34m        By default, data are dumped in a pickle file at the end of the video analysis.\u001b[0m\n",
      "\u001b[0;34m        Otherwise, data are written to disk on the fly using a \"shelf\"; i.e., a\u001b[0m\n",
      "\u001b[0;34m        pickle-based, persistent, database-like object by default, resulting in\u001b[0m\n",
      "\u001b[0;34m        constant memory footprint.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The following parameters are only relevant for multi-animal projects:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    auto_track: bool, optional, default=True\u001b[0m\n",
      "\u001b[0;34m        By default, tracking and stitching are automatically performed, producing the\u001b[0m\n",
      "\u001b[0;34m        final h5 data file. This is equivalent to the behavior for single-animal\u001b[0m\n",
      "\u001b[0;34m        projects.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        If ``False``, one must run ``convert_detections2tracklets`` and\u001b[0m\n",
      "\u001b[0;34m        ``stitch_tracklets`` afterwards, in order to obtain the h5 file.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This function has 3 related sub-calls:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    identity_only: bool, optional, default=False\u001b[0m\n",
      "\u001b[0;34m        If ``True`` and animal identity was learned by the model, assembly and tracking\u001b[0m\n",
      "\u001b[0;34m        rely exclusively on identity prediction.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    calibrate: bool, optional, default=False\u001b[0m\n",
      "\u001b[0;34m        Currently not supported by the PyTorch engine.\u001b[0m\n",
      "\u001b[0;34m        If ``True``, use training data to calibrate the animal assembly procedure. This\u001b[0m\n",
      "\u001b[0;34m        improves its robustness to wrong body part links, but requires very little\u001b[0m\n",
      "\u001b[0;34m        missing data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    n_tracks: int or None, optional, default=None\u001b[0m\n",
      "\u001b[0;34m        Number of tracks to reconstruct. By default, taken as the number of individuals\u001b[0m\n",
      "\u001b[0;34m        defined in the config.yaml. Another number can be passed if the number of\u001b[0m\n",
      "\u001b[0;34m        animals in the video is different from the number of animals the model was\u001b[0m\n",
      "\u001b[0;34m        trained on.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    use_openvino: str, optional\u001b[0m\n",
      "\u001b[0;34m        Only for the TensorFlow engine.\u001b[0m\n",
      "\u001b[0;34m        Use \"CPU\" for inference if OpenVINO is available in the Python environment.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    engine: Engine, optional, default = None.\u001b[0m\n",
      "\u001b[0;34m        The default behavior loads the engine for the shuffle from the metadata. You can\u001b[0m\n",
      "\u001b[0;34m        overwrite this by passing the engine as an argument, but this should generally\u001b[0m\n",
      "\u001b[0;34m        not be done.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    torch_kwargs:\u001b[0m\n",
      "\u001b[0;34m        Any extra parameters to pass to the PyTorch API, such as ``device`` which can\u001b[0m\n",
      "\u001b[0;34m        be used to specify the CUDA device to use for training.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns\u001b[0m\n",
      "\u001b[0;34m    -------\u001b[0m\n",
      "\u001b[0;34m    DLCScorer: str\u001b[0m\n",
      "\u001b[0;34m        the scorer used to analyze the videos\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Examples\u001b[0m\n",
      "\u001b[0;34m    --------\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Analyzing a single video on Windows\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> deeplabcut.analyze_videos(\u001b[0m\n",
      "\u001b[0;34m            'C:\\\\myproject\\\\reaching-task\\\\config.yaml',\u001b[0m\n",
      "\u001b[0;34m            ['C:\\\\yourusername\\\\rig-95\\\\Videos\\\\reachingvideo1.avi'],\u001b[0m\n",
      "\u001b[0;34m        )\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Analyzing a single video on Linux/MacOS\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> deeplabcut.analyze_videos(\u001b[0m\n",
      "\u001b[0;34m            '/analysis/project/reaching-task/config.yaml',\u001b[0m\n",
      "\u001b[0;34m            ['/analysis/project/videos/reachingvideo1.avi'],\u001b[0m\n",
      "\u001b[0;34m        )\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Analyze all videos of type ``avi`` in a folder\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> deeplabcut.analyze_videos(\u001b[0m\n",
      "\u001b[0;34m            '/analysis/project/reaching-task/config.yaml',\u001b[0m\n",
      "\u001b[0;34m            ['/analysis/project/videos'],\u001b[0m\n",
      "\u001b[0;34m            videotype='.avi',\u001b[0m\n",
      "\u001b[0;34m        )\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Analyze multiple videos\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> deeplabcut.analyze_videos(\u001b[0m\n",
      "\u001b[0;34m            '/analysis/project/reaching-task/config.yaml',\u001b[0m\n",
      "\u001b[0;34m            [\u001b[0m\n",
      "\u001b[0;34m                '/analysis/project/videos/reachingvideo1.avi',\u001b[0m\n",
      "\u001b[0;34m                '/analysis/project/videos/reachingvideo2.avi',\u001b[0m\n",
      "\u001b[0;34m            ],\u001b[0m\n",
      "\u001b[0;34m        )\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Analyze multiple videos with ``shuffle=2``\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> deeplabcut.analyze_videos(\u001b[0m\n",
      "\u001b[0;34m            '/analysis/project/reaching-task/config.yaml',\u001b[0m\n",
      "\u001b[0;34m            [\u001b[0m\n",
      "\u001b[0;34m                '/analysis/project/videos/reachingvideo1.avi',\u001b[0m\n",
      "\u001b[0;34m                '/analysis/project/videos/reachingvideo2.avi',\u001b[0m\n",
      "\u001b[0;34m            ],\u001b[0m\n",
      "\u001b[0;34m            shuffle=2,\u001b[0m\n",
      "\u001b[0;34m        )\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Analyze multiple videos with ``shuffle=2``, save results as an additional csv file\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> deeplabcut.analyze_videos(\u001b[0m\n",
      "\u001b[0;34m            '/analysis/project/reaching-task/config.yaml',\u001b[0m\n",
      "\u001b[0;34m            [\u001b[0m\n",
      "\u001b[0;34m                '/analysis/project/videos/reachingvideo1.avi',\u001b[0m\n",
      "\u001b[0;34m                '/analysis/project/videos/reachingvideo2.avi',\u001b[0m\n",
      "\u001b[0;34m            ],\u001b[0m\n",
      "\u001b[0;34m            shuffle=2,\u001b[0m\n",
      "\u001b[0;34m            save_as_csv=True,\u001b[0m\n",
      "\u001b[0;34m        )\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_shuffle_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0m_load_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtrainingsetindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainingsetindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmodelprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodelprefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mfrom\u001b[0m \u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_estimation_tensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manalyze_videos\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0muse_openvino\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# otherwise default comes from tensorflow API\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"use_openvino\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_openvino\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0manalyze_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mvideos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mvideotype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvideotype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtrainingsetindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainingsetindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mgputouse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgputouse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0msave_as_csv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_as_csv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0min_random_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_random_order\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdestfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdestfolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcropping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcropping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mTFGPUinference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTFGPUinference\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdynamic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmodelprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodelprefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mrobust_nframes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrobust_nframes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mallow_growth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0muse_shelve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_shelve\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mauto_track\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauto_track\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mn_tracks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_tracks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcalibrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalibrate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0midentity_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midentity_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPYTORCH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mfrom\u001b[0m \u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_estimation_pytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manalyze_videos\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0m_update_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgputouse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mbatchsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m\"batch_size\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\"You called analyze_videos with parameters ``batchsize={batchsize}\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\"`` and batch_size={torch_kwargs['batch_size']}. Only one is \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\"needed/used. Using batch size {torch_kwargs['batch_size']}\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mtorch_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0manalyze_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mvideos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvideos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mvideotype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvideotype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtrainingsetindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainingsetindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0msave_as_csv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_as_csv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdestfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdestfolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmodelprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodelprefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0muse_shelve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_shelve\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mrobust_nframes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrobust_nframes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mauto_track\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauto_track\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0midentity_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midentity_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcropping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcropping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m**\u001b[0m\u001b[0mtorch_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"This function is not implemented for {engine}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/.miniconda/envs/DEEPLABCUT/lib/python3.10/site-packages/deeplabcut/compat.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "deeplabcut.analyze_videos??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b42ec-2991-4a4b-93ed-cc587e65feb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.analyze_videos(config, videos, videotype='avi', shuffle=1, trainingsetindex=0, gputouse=0, save_as_csv=True, destfolder=None, dynamic=(True, .5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb2365f-3ab1-455f-abf7-abb605d8e003",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.filterpredictions(config, videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f8cd6f-afae-4bd8-a615-cb769c172587",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(config, videos, filtered=True, pcutoff=.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEPLABCUT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
